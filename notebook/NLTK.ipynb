{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from pyspark import SQLContext\n",
    "import pyspark.sql.functions as sql\n",
    "#from pyspark.sql.functions import udf, length\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import pyspark.ml.feature as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3232459\n"
     ]
    }
   ],
   "source": [
    "# Load Processed Parquet\n",
    "sqlContext = SQLContext(sc)\n",
    "notes = sqlContext.read.parquet(\"../data/idigbio_notes.parquet\")\n",
    "#idbdf = sqlContext.read.parquet(\"../data/idigbio-100k/occurrence.txt.parquet\")\n",
    "total_records = notes.count()\n",
    "print(total_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323628\n"
     ]
    }
   ],
   "source": [
    "# Small sample of the df\n",
    "notes_sm = notes.sample(withReplacement=False, fraction=0.1)\n",
    "notes_sm.cache()\n",
    "print(notes_sm.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total text in MB\n",
      "20153\n"
     ]
    }
   ],
   "source": [
    "# How much text is this?\n",
    "print(\"Total text in MB\")\n",
    "print(notes_sm.select(sql.sum(notes_sm['document_len'])).collect()[0][0] / 1024^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard phases:\n",
    "1. tokenize\n",
    "1. remove stop words\n",
    "1. stem\n",
    "1. frequency hist\n",
    "1. wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(uuid=u'5fa0d58e-1d6a-43ea-aad3-7d724c4ea231', occurrenceID=u'3124ecdf-1ed6-11e3-bfac-90b11c41863e', catalogNumber=u'192175', county=u'', institutionCode=u'KU', country=u'Papua New Guinea', countryCode=u'', stateProvince=u'Morobe', family=u'Staphylinidae', recordedBy=u'Anderson, Robert', order=u'Coleoptera', specificEpithet=u'', genus=u'Diestota', sex=u'', scientificName=u'Diestota', year=u'2000', month=u'2', fieldNotes=u'', occurrenceRemarks=u'', eventRemarks=u'berlese montane forest litter', document=u' berlese montane forest litter ', document_len=31, fieldNotes_len=0, eventRemarks_len=29, occurrenceRemarks_len=0, tokens=[u'', u'berlese', u'montane', u'forest', u'litter'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates a new column with a list of tokens in it, not a column of tokens\n",
    "tokenizer = feature.Tokenizer()\n",
    "#print(tokenizer.params)\n",
    "tokenizer.setParams(inputCol='document', outputCol='tokens')\n",
    "notes_tokens = tokenizer.transform(notes_sm)\n",
    "notes_tokens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'', u'berlese', u'montane', u'forest', u'litter', u'', u'see', u'field', u'notes', u'occasional']\n"
     ]
    }
   ],
   "source": [
    "# flatten to list of tokens\n",
    "tokens = notes_tokens.flatMap(lambda x: x['tokens'])\n",
    "print(tokens.take(10))\n",
    "#tokens.toDF(['token']).head()\n",
    "\n",
    "# Need to make this back in to a DF and then do word cloud or something"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
