{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identifying entities in notes\n",
    "\n",
    "Goal of this notebook is to determine how successful entity identification is using\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as sql\n",
    "import pyspark.sql.types as types\n",
    "#from pyspark.sql.functions import udf, length\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import pyspark.ml.feature as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3232459\n",
      "322657\n"
     ]
    }
   ],
   "source": [
    "# Load Processed Parquet\n",
    "sqlContext = SQLContext(sc)\n",
    "notes = sqlContext.read.parquet(\"../data/idigbio_notes.parquet\")\n",
    "total_records = notes.count()\n",
    "print(total_records)\n",
    "# Small sample of the df\n",
    "notes = notes.sample(withReplacement=False, fraction=0.1)\n",
    "notes.cache()\n",
    "print(notes.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|document                                                                                                                                                                                                       |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| 9:00-14:00. Collected in mixed primary and secondary growth, immature or regenerating forest, on limestone forest floor.                                                                                      |\n",
      "|WHITE PINE-HEMLOCK-BEECH-MAPLE-OAK   HEAVY LITTER MANY LARGE TREES                                                                                                                                             |\n",
      "|Annual herb, 40 cm. tall, tiny purple & green flowers, infrequent.                                                                                                                                             |\n",
      "|Substrate: soil and moss. AdditionalNotesPresent=Y.                                                                                                                                                            |\n",
      "|Numerous.  At least 3 other inulae in some place.  Flrs. and foliage have pointed appearance.  Grows up fairly straight from ground.                                                                           |\n",
      "|  new Delta Designs cabinet (2012 No 28 W. F. Henninger Collection; Cabinet:56; Drawer:14; VerbatimCollectionDate:September 15, 1891; specimen_state:skin (1 verbatimLocality:; Chester Co.; Pennsylvania; USA;|\n",
      "|  [17°10.4'S 145°38.0'E AUSTRALIA:QLD Mobo Creek Crater Danbulla State Forest 13-14.i.1999, YPT Coll. N.F. Johnson]                                                                                            |\n",
      "|Herbarium of The University of Tennessee                                                                                                                                                                       |\n",
      "| 2015-2300, on vegetation 1-5 m above ground                                                                                                                                                                   |\n",
      "| Old rock quarry, wet. Limestone soil. Abundant.                                                                                                                                                               |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for r in notes.head(20):\n",
    "#    print(r['document'] + \"\\n\")\n",
    "\n",
    "notes.select(notes[\"document\"]).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence detection\n",
    "\n",
    "Does splitting in to sentences matter? Is there enough information to do this with a natural language library or should things like \",\" \"[]\", and \"{}\" be worked in to address semi-structured data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'my', 'name', 'is', 'Mace', 'Windoo']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(s):\n",
    "    '''\n",
    "    Take a string and return a list of tokens split out from it\n",
    "    with the nltk library\n",
    "    '''\n",
    "    return nltk.tokenize.word_tokenize(s)\n",
    "\n",
    "tokens = tokenize(\"Hello, my name is Mace Windoo\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|tokens                                                                                                                                           |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[9:00-14:00, ., Collected, in, mixed, primary, and, secondary, growth, ,, immature, or, regenerating, forest, ,, on, limestone, forest, floor, .]|\n",
      "|[WHITE, PINE-HEMLOCK-BEECH-MAPLE-OAK, HEAVY, LITTER, MANY, LARGE, TREES]                                                                         |\n",
      "|[Annual, herb, ,, 40, cm, ., tall, ,, tiny, purple, &, green, flowers, ,, infrequent, .]                                                         |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udf_tokenize = sql.udf(tokenize, types.ArrayType(types.StringType()))\n",
    "\n",
    "notes_w_tokens = notes.withColumn('tokens', udf_tokenize(notes['document']))\n",
    "notes_w_tokens.select(notes_w_tokens[\"tokens\"]).show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- occurrenceID: string (nullable = true)\n",
      " |-- catalogNumber: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- institutionCode: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- countryCode: string (nullable = true)\n",
      " |-- stateProvince: string (nullable = true)\n",
      " |-- family: string (nullable = true)\n",
      " |-- recordedBy: string (nullable = true)\n",
      " |-- order: string (nullable = true)\n",
      " |-- specificEpithet: string (nullable = true)\n",
      " |-- genus: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- scientificName: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- fieldNotes: string (nullable = true)\n",
      " |-- occurrenceRemarks: string (nullable = true)\n",
      " |-- eventRemarks: string (nullable = true)\n",
      " |-- document: string (nullable = true)\n",
      " |-- document_len: integer (nullable = true)\n",
      " |-- fieldNotes_len: integer (nullable = true)\n",
      " |-- eventRemarks_len: integer (nullable = true)\n",
      " |-- occurrenceRemarks_len: integer (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "notes_w_tokens.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['9:00-14:00', '.', 'Collected']\n",
      "<type 'list'>\n",
      "<type 'str'>\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "t = [\"9:00-14:00\", \".\", \"Collected\"]\n",
    "pos = nltk.pos_tag(t)\n",
    "print(t)\n",
    "print(type(t))\n",
    "print(type(t[0]))\n",
    "print(type(t[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tag': 'NNP', 'word': 'Hello'}, {'tag': ',', 'word': ','}, {'tag': 'PRP$', 'word': 'my'}, {'tag': 'NN', 'word': 'name'}, {'tag': 'VBZ', 'word': 'is'}, {'tag': 'NNP', 'word': 'Mace'}, {'tag': 'NNP', 'word': 'Windoo'}]\n",
      "<type 'list'>\n",
      "<type 'dict'>\n",
      "<type 'str'>\n",
      "{'tag': 'NNP', 'word': 'Hello'}\n"
     ]
    }
   ],
   "source": [
    "def part_of_speech(t):\n",
    "    '''\n",
    "    With a list of tokens, mark their part of speech and return\n",
    "    a list dicts (no native tuple type in dataframes it seems).\n",
    "    '''\n",
    "    pos = nltk.pos_tag(t)\n",
    "    retval = []\n",
    "    for p in pos:\n",
    "        retval.append({\"word\": p[0], \"tag\": p[1]})\n",
    "    return retval\n",
    "\n",
    "pos = part_of_speech(tokens)\n",
    "print(pos)\n",
    "print(type(pos))\n",
    "print(type(pos[0]))\n",
    "print(type(pos[0][\"tag\"]))\n",
    "print(pos[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|pos                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Map(word -> 9:00-14:00, tag -> CD), Map(word -> ., tag -> .), Map(word -> Collected, tag -> NNP), Map(word -> in, tag -> IN), Map(word -> mixed, tag -> VBN), Map(word -> primary, tag -> JJ), Map(word -> and, tag -> CC), Map(word -> secondary, tag -> JJ), Map(word -> growth, tag -> NN), Map(word -> ,, tag -> ,), Map(word -> immature, tag -> NN), Map(word -> or, tag -> CC), Map(word -> regenerating, tag -> VBG), Map(word -> forest, tag -> NN), Map(word -> ,, tag -> ,), Map(word -> on, tag -> IN), Map(word -> limestone, tag -> NN), Map(word -> forest, tag -> NN), Map(word -> floor, tag -> NN), Map(word -> ., tag -> .)]|\n",
      "|[Map(word -> WHITE, tag -> NNP), Map(word -> PINE-HEMLOCK-BEECH-MAPLE-OAK, tag -> NNP), Map(word -> HEAVY, tag -> NNP), Map(word -> LITTER, tag -> NNP), Map(word -> MANY, tag -> NNP), Map(word -> LARGE, tag -> NNP), Map(word -> TREES, tag -> NNP)]                                                                                                                                                                                                                                                                                                                                                                                         |\n",
      "|[Map(word -> Annual, tag -> JJ), Map(word -> herb, tag -> NN), Map(word -> ,, tag -> ,), Map(word -> 40, tag -> CD), Map(word -> cm, tag -> NN), Map(word -> ., tag -> .), Map(word -> tall, tag -> NN), Map(word -> ,, tag -> ,), Map(word -> tiny, tag -> JJ), Map(word -> purple, tag -> NN), Map(word -> &, tag -> CC), Map(word -> green, tag -> JJ), Map(word -> flowers, tag -> NNS), Map(word -> ,, tag -> ,), Map(word -> infrequent, tag -> NN), Map(word -> ., tag -> .)]                                                                                                                                                            |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "udf_part_of_speech = sql.udf(part_of_speech, types.ArrayType(\n",
    "                                    types.MapType(\n",
    "                                        types.StringType(),\n",
    "                                        types.StringType()\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "notes_w_tokens2 = notes_w_tokens.withColumn('pos', \n",
    "                                            udf_part_of_speech(notes_w_tokens['tokens']))\n",
    "\n",
    "notes_w_tokens2.select(notes_w_tokens2[\"pos\"]).show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- uuid: string (nullable = true)\n",
      " |-- occurrenceID: string (nullable = true)\n",
      " |-- catalogNumber: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- institutionCode: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- countryCode: string (nullable = true)\n",
      " |-- stateProvince: string (nullable = true)\n",
      " |-- family: string (nullable = true)\n",
      " |-- recordedBy: string (nullable = true)\n",
      " |-- order: string (nullable = true)\n",
      " |-- specificEpithet: string (nullable = true)\n",
      " |-- genus: string (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- scientificName: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- fieldNotes: string (nullable = true)\n",
      " |-- occurrenceRemarks: string (nullable = true)\n",
      " |-- eventRemarks: string (nullable = true)\n",
      " |-- document: string (nullable = true)\n",
      " |-- document_len: integer (nullable = true)\n",
      " |-- fieldNotes_len: integer (nullable = true)\n",
      " |-- eventRemarks_len: integer (nullable = true)\n",
      " |-- occurrenceRemarks_len: integer (nullable = true)\n",
      " |-- tokens: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- pos: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "notes_w_tokens2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|pos[0][word]|\n",
      "+------------+\n",
      "|9:00-14:00  |\n",
      "|WHITE       |\n",
      "|Annual      |\n",
      "+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Can we work with maps natively?\n",
    "notes_w_tokens2.select(notes_w_tokens2[\"pos\"][0][\"word\"]).show(3, truncate=False)\n",
    "# YES!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'name', 'Mace', 'Windoo']\n"
     ]
    }
   ],
   "source": [
    "# Split out words by type\n",
    "# Can't figure out how to access elements of a map in a filter so \n",
    "# build something that filters the lists for us.\n",
    "def find_pos(pos, part):\n",
    "    '''\n",
    "    Take a list of dicts that represent words tagged with\n",
    "    pos information and return a list of words that match\n",
    "    the requested pos\n",
    "    '''\n",
    "    retval = []\n",
    "    for p in pos:\n",
    "        if p[\"tag\"].startswith(part):\n",
    "            retval.append(p[\"word\"])\n",
    "    return retval\n",
    "\n",
    "print(find_pos(pos, \"NN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can't figure out how to pass a single string to a UDF\n",
    "find_nouns_udf = sql.udf(lambda x: find_pos(x, \"NN\"), types.ArrayType(types.StringType()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|Collected|\n",
      "|   growth|\n",
      "| immature|\n",
      "+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nouns = notes_w_tokens2\\\n",
    "    .select(sql.explode(find_nouns_udf(notes_w_tokens2[\"pos\"])).alias(\"word\"))\n",
    "      \n",
    "nouns.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                word|\n",
      "+--------------------+\n",
      "|           Collected|\n",
      "|              growth|\n",
      "|            immature|\n",
      "|              forest|\n",
      "|           limestone|\n",
      "|              forest|\n",
      "|               floor|\n",
      "|               WHITE|\n",
      "|PINE-HEMLOCK-BEEC...|\n",
      "|               HEAVY|\n",
      "|              LITTER|\n",
      "|                MANY|\n",
      "|               LARGE|\n",
      "|               TREES|\n",
      "|                herb|\n",
      "|                  cm|\n",
      "|                tall|\n",
      "|              purple|\n",
      "|             flowers|\n",
      "|          infrequent|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nouns\\\n",
    "    .na.drop().show()\n",
    "    \n",
    "\n",
    "#    .groupBy(\"word\")\\\n",
    "#    .count()\\\n",
    "#    .show(3)\n",
    "     #.orderBy(\"count\", ascending=False)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And some verbs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
