{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting with chunking classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ":0: FutureWarning: IPython widgets are experimental and may change in the future.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import os\n",
    "from pyspark import SQLContext\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as sql\n",
    "import pyspark.sql.types as types\n",
    "#from pyspark.sql.functions import udf, length\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import pyspark.ml.feature as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3230857\n",
      "32028\n"
     ]
    }
   ],
   "source": [
    "# Load Processed Parquet\n",
    "sqlContext = SQLContext(sc)\n",
    "notes = sqlContext.read.parquet(\"../data/idigbio_notes.parquet\")\n",
    "total_records = notes.count()\n",
    "print(total_records)\n",
    "# Small sample of the df\n",
    "notes = notes.sample(withReplacement=False, fraction=0.01)\n",
    "notes.cache()\n",
    "print(notes.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------+\n",
      "|tokens                                                                                    |\n",
      "+------------------------------------------------------------------------------------------+\n",
      "|[Lloydia, 1965, 28, :, 125, .]                                                            |\n",
      "|[SEE, GVF, REG., 0191, FOR, MORE, DATA, See, GVF, 191, (, sta., 70, ), for, more, data, .]|\n",
      "|[flight, intercept, trap]                                                                 |\n",
      "|[Mixed, live, oak, and, blue, oak, with, chapparal, scrub]                                |\n",
      "|[BMNH, (, E, ), 1013748]                                                                  |\n",
      "+------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.tokens import Tokens\n",
    "tokens = Tokens()\n",
    "udf_tokenize = sql.udf(tokens.tokenize, types.ArrayType(types.StringType()))\n",
    "notes_w_tokens = notes.withColumn('tokens', udf_tokenize(notes['document']))\n",
    "notes_w_tokens\\\n",
    "    .select(sql.col(\"tokens\"))\\\n",
    "    .show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|pos                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Map(word -> Lloydia, tag -> NNP), Map(word -> 1965, tag -> CD), Map(word -> 28, tag -> CD), Map(word -> :, tag -> :), Map(word -> 125, tag -> CD), Map(word -> ., tag -> .)]                                                                                                                                                                                                                                                                                                                                                                       |\n",
      "|[Map(word -> SEE, tag -> NNP), Map(word -> GVF, tag -> NNP), Map(word -> REG., tag -> NNP), Map(word -> 0191, tag -> CD), Map(word -> FOR, tag -> NNP), Map(word -> MORE, tag -> NNP), Map(word -> DATA, tag -> NNP), Map(word -> See, tag -> NNP), Map(word -> GVF, tag -> NNP), Map(word -> 191, tag -> CD), Map(word -> (, tag -> CD), Map(word -> sta., tag -> NNP), Map(word -> 70, tag -> CD), Map(word -> ), tag -> CD), Map(word -> for, tag -> IN), Map(word -> more, tag -> JJR), Map(word -> data, tag -> NNS), Map(word -> ., tag -> .)]|\n",
      "|[Map(word -> flight, tag -> NN), Map(word -> intercept, tag -> VBD), Map(word -> trap, tag -> NN)]                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n",
      "|[Map(word -> Mixed, tag -> NNP), Map(word -> live, tag -> VBP), Map(word -> oak, tag -> NN), Map(word -> and, tag -> CC), Map(word -> blue, tag -> JJ), Map(word -> oak, tag -> NN), Map(word -> with, tag -> IN), Map(word -> chapparal, tag -> JJ), Map(word -> scrub, tag -> NN)]                                                                                                                                                                                                                                                                |\n",
      "|[Map(word -> BMNH, tag -> NNP), Map(word -> (, tag -> :), Map(word -> E, tag -> NNP), Map(word -> ), tag -> :), Map(word -> 1013748, tag -> CD)]                                                                                                                                                                                                                                                                                                                                                                                                    |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.pos_tags import PosTags\n",
    "pos_tags = PosTags()\n",
    "udf_part_of_speech = sql.udf(pos_tags.tag, types.ArrayType(\n",
    "                                    types.MapType(\n",
    "                                        types.StringType(),\n",
    "                                        types.StringType()\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "notes_w_tokens2 = notes_w_tokens.withColumn('pos', \n",
    "                                            udf_part_of_speech(notes_w_tokens['tokens']))\n",
    "notes_w_tokens2\\\n",
    "    .select(sql.col(\"pos\"))\\\n",
    "    .show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write out this small set of tagged records to build a training set by manually adding a iob tag\n",
    "notes_w_tokens2.write.json(\"../data/chunker_pre_training.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ok, with that training data we've got a chunker developed\n",
    "from lib.chunks import Chunks\n",
    "chunker = Chunks()\n",
    "training_data = chunker.load_training_data(\"../data/chunker_training_50_fixed.json\")\n",
    "chunker.train(training_data)\n",
    "\n",
    "def make_phrases(s):\n",
    "    return chunker.assemble(chunker.tag(s))\n",
    "\n",
    "make_phrases_udf = sql.udf(make_phrases, types.ArrayType(types.MapType(\n",
    "            types.StringType(), types.StringType()\n",
    "        )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191\n",
      "+---------------------------------------------------+\n",
      "|phrase                                             |\n",
      "+---------------------------------------------------+\n",
      "|eucalyptus oil                                     |\n",
      "|ridge litter                                       |\n",
      "|forest flight intercept trap                       |\n",
      "|mycoportal does recognize                          |\n",
      "|may be wrong                                       |\n",
      "|forest litter                                      |\n",
      "|field label                                        |\n",
      "|blacklight trap                                    |\n",
      "|flor cilidro                                       |\n",
      "|fleshy terrestrial polypore                        |\n",
      "|lip pale blue                                      |\n",
      "|de color guinda                                    |\n",
      "|litter montane evergreen forest litter             |\n",
      "|see station sheet                                  |\n",
      "|sandy rivershore                                   |\n",
      "|slide collection                                   |\n",
      "|purple to dark lavender                            |\n",
      "|pit trap                                           |\n",
      "|engelmannii- abies lasiocarpa stand                |\n",
      "|mercury vapor lite                                 |\n",
      "|spruce bog                                         |\n",
      "|center clearing                                    |\n",
      "|caudal coloration                                  |\n",
      "|gland chemestry                                    |\n",
      "|field notes                                        |\n",
      "|pale lavender                                      |\n",
      "|montane berlese forest litter                      |\n",
      "|returned to river                                  |\n",
      "|and bristly leaves                                 |\n",
      "|invertebrate collection                            |\n",
      "|mountain forest/ cloud forest flight intercept trap|\n",
      "|atrraction trap                                    |\n",
      "|malaise trap                                       |\n",
      "|cloud forest litter                                |\n",
      "|attracted to wet sand                              |\n",
      "|past flowering                                     |\n",
      "|flor color lila con petalo inferior blanco         |\n",
      "|carrion trap                                       |\n",
      "|stream valley                                      |\n",
      "|hard to read                                       |\n",
      "|elfin forest litter                                |\n",
      "|red to dim gray                                    |\n",
      "|turkey nest                                        |\n",
      "|sheehy/aug2003 see station sheet                   |\n",
      "|rain forest flight intercept trap                  |\n",
      "|rye grass                                          |\n",
      "|montane forest litter                              |\n",
      "|morado obscuro                                     |\n",
      "|premontane berlese forest litter                   |\n",
      "|leathery polypore                                  |\n",
      "+---------------------------------------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "phrases = notes_w_tokens2\\\n",
    "    .withColumn(\"phrases\", make_phrases_udf(sql.col(\"pos\")))\\\n",
    "    .select(sql.explode(sql.col(\"phrases\")).alias(\"text\"))\\\n",
    "    .filter(sql.col(\"text\")[\"tag\"] == \"NP\")\\\n",
    "    .select(sql.lower(sql.col(\"text\")[\"phrase\"]).alias(\"phrase\"))\\\n",
    "    .groupBy(sql.col(\"phrase\"))\\\n",
    "    .count()\n",
    "\n",
    "\n",
    "print(phrases.count())\n",
    "phrases.select(sql.col(\"phrase\")).show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
